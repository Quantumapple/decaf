{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot3 as up\n",
    "import mplhep as hep\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from cycler import cycler\n",
    "\n",
    "hep.style.use('CMS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "    'dyjetsMC': {'color': '#e5ccff', 'name': 'DY+jets'},\n",
    "    'hbbMC': {'color': '#ccccff', 'name': r'$H\\rightarrow b\\bar{b}$'},\n",
    "    'qcdMC': {'color': '#ffccff', 'name': 'QCD'},\n",
    "    'vvMC': {'color': '#ffff99', 'name': 'VV'},\n",
    "    'st': {'color': '#ff9999', 'name': 'Single t'},\n",
    "    'stMC': {'color': '#ff9999', 'name': 'Single t'},\n",
    "    'tt': {'color': '#ffcc66', 'name': r'$t\\bar{t}$'},\n",
    "    'ttMC': {'color': '#ffcc66', 'name': r'$t\\bar{t}$'},\n",
    "    'wjets': {'color': '#ccffcc', 'name': 'W+jets'},\n",
    "    'wjetsMC': {'color': '#ccffcc', 'name': 'W+jets'},\n",
    "    'zjets': {'color': '#99ffff', 'name': 'Z+jets'},\n",
    "    'zjetsMC': {'color': '#99ffff', 'name': 'Z+jets'},\n",
    "}\n",
    "\n",
    "recoilDict = {\n",
    "    '0':'[250, 310) GeV',\n",
    "    '1':'[310, 370) GeV',\n",
    "    '2':'[370, 470) GeV',\n",
    "    '3':'[470, 590) GeV',\n",
    "    '4':'[590, inf] GeV'\n",
    "}\n",
    "\n",
    "regionDict = {\n",
    "    'sr_pass':'Signal Region',\n",
    "    'sr_fail':'Z+jets Control Region',\n",
    "    'wecr_pass':'W+jets Single Electron \\\"Pass\\\" Control Region',\n",
    "    'wecr_fail':'W+jets Single Electron \\\"Fail\\\" Control Region',\n",
    "    'wmcr_pass':'W+jets Single Muon \\\"Pass\\\" Control Region',\n",
    "    'wmcr_fail':'W+jets Single Muon \\\"Fail\\\" Control Region',\n",
    "    'tecr_pass':'Top-Pair Single Electron Control Region',\n",
    "    'tmcr_pass':'Top-Pair Single Muon Control Region',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(input_file):\n",
    "\n",
    "    years = ['2016', '2017', '2018']\n",
    "    region = 'sr'\n",
    "    recoil_tags = [str(i) for i in range(5)]\n",
    "    categories = ['pass', 'fail']\n",
    "\n",
    "    outputs = {}\n",
    "\n",
    "    for itag in recoil_tags:\n",
    "        for category in categories:\n",
    "\n",
    "            merged_data = None\n",
    "\n",
    "            for year in years:\n",
    "                identifier40to120 = f'{region}{year}{category}mass40to120recoil{itag}'\n",
    "                identifier120to300 = f'{region}{year}{category}mass120to300recoil{itag}'\n",
    "\n",
    "                prefit_dir40to120 = input_file[identifier40to120+'_prefit']\n",
    "                prefit_dir120to300 = input_file[identifier120to300+'_prefit']\n",
    "\n",
    "                data40to120 = prefit_dir40to120[\"data_obs\"].values\n",
    "                data120to300 = prefit_dir120to300[\"data_obs\"].values\n",
    "\n",
    "                data = np.concatenate((data40to120, data120to300), axis=None)\n",
    "\n",
    "                if merged_data is None:\n",
    "                    merged_data = np.array(data)  # Initialize as a NumPy array\n",
    "                else:\n",
    "                    merged_data += data  # Element-wise addition\n",
    "\n",
    "            outputs[f'{category}_{itag}'] = merged_data\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def merge_bkg(input_file, processes40to120, processes120to300):\n",
    "\n",
    "    years = ['2016', '2017', '2018']\n",
    "    region = 'sr'\n",
    "    recoil_tags = [str(i) for i in range(5)]\n",
    "    categories = ['pass', 'fail']\n",
    "\n",
    "    edges = [40.,  50.,  60.,  70.,  80.,  90., 100., 120., 150., 180., 240., 300.]\n",
    "\n",
    "    outputs = {}\n",
    "\n",
    "    for itag in recoil_tags:\n",
    "        for category in categories:\n",
    "\n",
    "            sum_prefit = np.zeros(len(edges)-1)\n",
    "            sum_postfit = np.zeros(len(edges)-1)\n",
    "            sum_postfit_variance = np.zeros(len(edges)-1)\n",
    "\n",
    "            for year in years:\n",
    "                identifier40to120 = f'{region}{year}{category}mass40to120recoil{itag}'\n",
    "                identifier120to300 = f'{region}{year}{category}mass120to300recoil{itag}'\n",
    "\n",
    "                prefit_dir40to120 = input_file[identifier40to120+'_prefit']\n",
    "                prefit_dir120to300 = input_file[identifier120to300+'_prefit']\n",
    "\n",
    "                postfit_dir40to120 = input_file[identifier40to120+'_postfit']\n",
    "                postfit_dir120to300 = input_file[identifier120to300+'_postfit']\n",
    "\n",
    "                for (i, j) in zip(processes40to120, processes120to300):\n",
    "\n",
    "                    try:\n",
    "                        prefit40to120 = prefit_dir40to120[i].values\n",
    "                        postfit40to120 = postfit_dir40to120[i].values\n",
    "                        postfit40to120_variance = np.minimum(postfit40to120, postfit_dir40to120[i].variances)\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "                    try:\n",
    "                        prefit120to300 = prefit_dir120to300[j].values\n",
    "                        postfit120to300 = postfit_dir120to300[j].values\n",
    "                        postfit120to300_variance = np.minimum(postfit120to300, postfit_dir120to300[j].variances)\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "                    prefit_bin = np.concatenate((prefit40to120, prefit120to300), axis=None)\n",
    "                    postfit_bin = np.concatenate((postfit40to120, postfit120to300), axis=None)\n",
    "                    postfit_bin_variance = np.concatenate((postfit40to120_variance, postfit120to300_variance), axis=None)\n",
    "                    sum_prefit += prefit_bin\n",
    "                    sum_postfit += postfit_bin\n",
    "                    sum_postfit_variance += postfit_bin_variance\n",
    "\n",
    "            outputs[f'{category}_{itag}_prefit'] = sum_prefit\n",
    "            outputs[f'{category}_{itag}_postfit'] = sum_postfit\n",
    "            outputs[f'{category}_{itag}_postfit_variance'] = sum_postfit_variance\n",
    "\n",
    "    return outputs\n",
    "\n",
    "def merge_individual_bkg(input_file, processes40to120, processes120to300):\n",
    "\n",
    "    from collections import defaultdict\n",
    "\n",
    "    years = ['2016', '2017', '2018']\n",
    "    region = 'sr'\n",
    "    recoil_tags = [str(i) for i in range(5)]\n",
    "    categories = ['pass', 'fail']\n",
    "\n",
    "    process_bin = {}\n",
    "    process_bin_variance = {}\n",
    "\n",
    "    for itag in recoil_tags:\n",
    "        for category in categories:\n",
    "\n",
    "            for year in years:\n",
    "                identifier40to120 = f'{region}{year}{category}mass40to120recoil{itag}'\n",
    "                identifier120to300 = f'{region}{year}{category}mass120to300recoil{itag}'\n",
    "\n",
    "                postfit_dir40to120 = input_file[identifier40to120+'_postfit']\n",
    "                postfit_dir120to300 = input_file[identifier120to300+'_postfit']\n",
    "\n",
    "                for (i, j) in zip(processes40to120, processes120to300):\n",
    "\n",
    "                    try:\n",
    "                        postfit40to120 = postfit_dir40to120[i].values\n",
    "                        postfit40to120_variance = np.minimum(postfit40to120, postfit_dir40to120[i].variances)\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "                    try:\n",
    "                        postfit120to300 = postfit_dir120to300[j].values\n",
    "                        postfit120to300_variance = np.minimum(postfit120to300, postfit_dir120to300[j].variances)\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "                    postfit_bin = np.concatenate((postfit40to120, postfit120to300), axis=None)\n",
    "                    postfit_bin_variance = np.concatenate((postfit40to120_variance, postfit120to300_variance), axis=None)\n",
    "\n",
    "                    key = f'{itag}_{category}_{i}_{j}'\n",
    "\n",
    "                    if not key in process_bin.keys():\n",
    "                        process_bin[key] = postfit_bin\n",
    "                        process_bin_variance[key] = postfit_bin_variance\n",
    "                    else:\n",
    "                        process_bin[key] += postfit_bin\n",
    "                        process_bin_variance[key] += postfit_bin_variance\n",
    "\n",
    "    return process_bin, process_bin_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load input file\n",
    "f = up.open(\"../hists/darkhiggs.postfit\")\n",
    "\n",
    "### Merged data\n",
    "data_values_dict = merge_data(f)\n",
    "\n",
    "### Merged MC\n",
    "processes40to120 = ['hbbMC', 'dyjetsMC', 'qcdMC', 'vvMC', 'stMC', 'ttMC', 'ttMC', 'wjets', 'wjetsMC', 'zjets', 'zjetsMC']\n",
    "processes120to300 = ['hbbMC', 'dyjetsMC', 'qcdMC', 'vvMC', 'stMC', 'tt',  'ttMC', 'wjets', 'wjetsMC', 'zjets', 'zjetsMC']\n",
    "\n",
    "total_bkg_dict = merge_bkg(f, processes40to120, processes120to300)\n",
    "indiv_mc, indiv_mc_variance = merge_individual_bkg(f, processes40to120, processes120to300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_values_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_bkg_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indiv_mc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 5, figsize=(40,12), sharex='col', sharey='row',\n",
    "                                gridspec_kw=dict(height_ratios=[3, 1], hspace=0.15, wspace=0.))\n",
    "errps = {'hatch':'////', 'facecolor':'none', 'lw': 0, 'color': 'k', 'alpha': 0.3}\n",
    "edges = [40.,  50.,  60.,  70.,  80.,  90., 100., 120., 150., 180., 240., 300.]\n",
    "\n",
    "fig.supxlabel('AK15 Soft-Drop Mass [GeV]', fontsize=40)\n",
    "\n",
    "for k in range(5):\n",
    "\n",
    "    ax=axs[0][k]\n",
    "    rax=axs[1][k]\n",
    "\n",
    "    ax.text(s=f'$U$ $\\in$ {recoilDict[str(k)]}',x=0.02,y=0.92, fontsize=35,transform=ax.transAxes)\n",
    "    ax._get_lines.prop_cycler = ax._get_patches_for_fill.prop_cycler\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(1e-2, 1e+5)\n",
    "\n",
    "    colors=[]\n",
    "    mc_process_data = []\n",
    "    mc_names = []\n",
    "    for mc in indiv_mc.keys():\n",
    "        if mc.split('_')[0] != str(k):\n",
    "            continue\n",
    "        elif mc.split('_')[1] == 'fail':\n",
    "            continue\n",
    "        colors.append(config_dict[mc.split('_')[-1]]['color'])\n",
    "        mc_process_data.append(indiv_mc[mc])\n",
    "        mc_names.append(config_dict[mc.split('_')[-1]]['name'])\n",
    "\n",
    "    ax.set_prop_cycle(cycler(color=colors))\n",
    "\n",
    "    ### Try to draw stack plots\n",
    "    hep.histplot(mc_process_data, edges, ax=ax, stack=True,\n",
    "                    histtype='fill', edgecolor = 'k', linewidth=3, label=mc_names)\n",
    "\n",
    "    ### Draw stat uncs.\n",
    "    y1 = total_bkg_dict[f'pass_{k}_postfit'] - np.sqrt(total_bkg_dict[f'pass_{k}_postfit_variance'])\n",
    "    y1 = np.append(y1, 0)\n",
    "    y2 = total_bkg_dict[f'pass_{k}_postfit'] + np.sqrt(total_bkg_dict[f'pass_{k}_postfit_variance'])\n",
    "    y2 = np.append(y2, 0)\n",
    "    ax.fill_between(\n",
    "        x = edges,\n",
    "        y1 = y1,\n",
    "        y2 = y2,\n",
    "        step = 'post',\n",
    "        **errps, label='Stat. Unc.'\n",
    "    )\n",
    "\n",
    "    hep.histplot(total_bkg_dict[f'pass_{k}_postfit'], edges, ax=ax, label=[\"Postift\"], color='b', linewidth=6)\n",
    "    hep.histplot(total_bkg_dict[f'pass_{k}_prefit'], edges, ax=ax, label=[\"Prefit\"], color='r',\n",
    "                    linestyle='dashed', linewidth=6)\n",
    "\n",
    "    ### Call data ###\n",
    "    hep.histplot(data_values_dict[f'pass_{k}'], edges, ax=ax, histtype='errorbar', label=\"Data\", color='k', markersize=20)\n",
    "\n",
    "    #### Draw ratio ####\n",
    "    hep.histplot(data_values_dict[f'pass_{k}']/total_bkg_dict[f'pass_{k}_prefit'], edges, yerr=np.sqrt(data_values_dict[f'pass_{k}'])/total_bkg_dict[f'pass_{k}_prefit'], ax=rax, histtype='errorbar',\n",
    "                     color='r', capsize=10, label=\"Prefit\", markersize=20)\n",
    "    hep.histplot(data_values_dict[f'pass_{k}']/total_bkg_dict[f'pass_{k}_postfit'], edges, yerr=np.sqrt(data_values_dict[f'pass_{k}'])/total_bkg_dict[f'pass_{k}_postfit'], ax=rax, histtype='errorbar',\n",
    "                    color='b', capsize=10, label=\"Postfit\", markersize=20)\n",
    "\n",
    "    y1 = 1.- np.sqrt(total_bkg_dict[f'pass_{k}_postfit'])/total_bkg_dict[f'pass_{k}_postfit']\n",
    "    y1 = np.append(y1, 0)\n",
    "    y2 = 1.+ np.sqrt(total_bkg_dict[f'pass_{k}_postfit'])/total_bkg_dict[f'pass_{k}_postfit']\n",
    "    y2 = np.append(y2, 0)\n",
    "\n",
    "    rax.fill_between(\n",
    "        x = edges,\n",
    "        y1 = y1,\n",
    "        y2 = y2,\n",
    "        step='post',\n",
    "        **errps, label='Stat. Uncs.'\n",
    "    )\n",
    "\n",
    "    rax.axhline(1, ls='--', color='k')\n",
    "    ymax=abs(rax.get_ylim()[1])*1.1\n",
    "    ymin=1.-(ymax-1.)\n",
    "    rax.set_ylim(max(ymin,0),min(ymax,2))\n",
    "    rax.set_xlim(40, 300)\n",
    "\n",
    "    if k == 0:\n",
    "        hep.cms.text(ax=ax, loc=0, text='Preliminary',fontsize=45)\n",
    "        ax.set_ylabel('Events/GeV', fontsize=40)\n",
    "        ax.tick_params(axis='y', labelsize=30)\n",
    "        ax.set_xticks([50,100,150,200,250])\n",
    "        rax.set_ylabel('Obs/Exp', fontsize=40)\n",
    "        rax.tick_params(axis='y', labelsize=30)\n",
    "        rax.tick_params(axis='x', labelsize=30)\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "    else:\n",
    "        ax.set_xticks([50,100,150,200,250])\n",
    "        rax.tick_params(axis='x', labelsize=30)\n",
    "\n",
    "    if k == 4:\n",
    "\n",
    "        ### Lumi text\n",
    "        hep.cms.lumitext(ax=ax, text=r\"138 fb$^{-1}$, 2016-2018 (13 TeV)\", fontsize=45)\n",
    "\n",
    "        #### Legend\n",
    "        order = [11, 9, 10, 7, 6, 5, 4, 3, 2, 1, 0, 8]\n",
    "        ax.legend([handles[idx] for idx in order], [labels[idx] for idx in order],\n",
    "                     loc='center left', fontsize=20, ncol=3, bbox_to_anchor=(-0.02, 0.72))\n",
    "\n",
    "        handles, labels = rax.get_legend_handles_labels()\n",
    "        order = [1, 2, 0]\n",
    "        rax.legend([handles[idx] for idx in order], [labels[idx] for idx in order],\n",
    "                   loc='center left', fontsize=20, ncol=3, bbox_to_anchor=(0.0, 0.12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "packages",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
